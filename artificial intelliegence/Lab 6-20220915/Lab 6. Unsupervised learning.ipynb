{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook, by [felipe.alonso@urjc.es](mailto:felipe.alonso@urjc.es)\n",
    "\n",
    "In this notebook we will analyze clustering methods over the Pima Indiand Diabetes dataset.\n",
    "\n",
    "# Table of Contents\n",
    "\n",
    "0. [Preliminaries](#preliminaries)\n",
    "1. [K-means](#k_means) \n",
    "2. [Hierchical clustering](#hierarchical)\n",
    "3. [Project Ideas](#ideas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='preliminaries'></a>\n",
    "# 0 . Preliminaries\n",
    "\n",
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# your code here\n",
    "# ... add as many libraries as you want\n",
    "\n",
    "from src.utils import plot_scatter, plot_silhouette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "In this lab exercise you are using the Pima Indian Diabetes data. Your hypothesis is that **there might be groups of patients with similar behavior** and you want to get some insights about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ddbb import load_pima_indian\n",
    "\n",
    "X, y = load_pima_indian('./data/pima_indian_diabetes.csv')\n",
    "feat_names = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='k_means'></a>\n",
    "# 1. K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X1 = X[['bmi','glucose']].values\n",
    "X1 = StandardScaler().fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# build the clustering model\n",
    "k = 2\n",
    "kmeans = KMeans(n_clusters = k).fit(X1)\n",
    "\n",
    "# Centroids \n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Labels\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# do the plotting\n",
    "plot_scatter(X1,'k = ' + str(k), cluster_labels, centroids)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we use the target variable `y`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the plotting\n",
    "plot_scatter(X1,'k = ' + str(k), y, centroids)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careful here, the purpose is to group our observations not classify them (so there might be subgroups within our observations having the same or differente outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many cluster are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = range(1,15)\n",
    "\n",
    "inertia = []\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k).fit(X1)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    \n",
    "plt.plot(K,inertia,'.-')\n",
    "plt.xlabel('# of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the silhouette analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=7).fit(X1)\n",
    "plot_silhouette(X1,k,kmeans.labels_,kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's analyze our observations depending on the cluster label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X.copy()\n",
    "df['cluster_label'] = cluster_labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.cluster_label==3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.cluster_label==0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class = \"alert alert-info\">\n",
    "<b>Note:</b> You can use either <b>cluster_labels</b> or <b>outcome</b> in the above representation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA & K-means\n",
    "\n",
    "Two options here:\n",
    "    \n",
    "1. K-means + PCA representation\n",
    "2. PCA dimensionality reduction + K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# scaling\n",
    "X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Number of components\n",
    "pca = PCA().fit(X_scaled)\n",
    "X_pca = PCA(n_components=2).fit_transform(X_scaled)\n",
    "\n",
    "# Data visualization (just 2 components)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_),'.-')\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.bar(range(pca.n_components_), pca.explained_variance_ratio_, color='black')\n",
    "plt.xlabel('PCA features')\n",
    "plt.ylabel('variance %')\n",
    "plt.xticks(range(pca.n_components_))\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.scatter(X_pca[:,0],X_pca[:,1], c=y)\n",
    "plt.xlabel('$x_1$ (PCA)',fontsize=16)\n",
    "plt.ylabel('$x_2$ (PCA)',fontsize=16)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.scatter(X_pca[:,0],X_pca[:,1], c=cluster_labels)\n",
    "plt.xlabel('$x_1$ (PCA)',fontsize=16)\n",
    "plt.ylabel('$x_2$ (PCA)',fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = PCA(n_components=2).fit_transform(X_scaled)\n",
    "kmeans = KMeans(n_clusters = k).fit(X_pca)\n",
    "\n",
    "# Centroids \n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# Labels\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# do the plotting\n",
    "plot_scatter(X_pca,'k = ' + str(k), cluster_labels, centroids)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='hierarchical'></a>\n",
    "# 2. Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "Z = linkage(X1, 'ward')\n",
    "dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agg = AgglomerativeClustering(n_clusters=4).fit(X1)\n",
    "plot_scatter(X1,'Hierarchical clustering', agg.labels_) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='ideas'></a>\n",
    "# Project Ideas\n",
    "\n",
    "\n",
    "Here there are some ideas that you might want to consider for your project:\n",
    "\n",
    "- Apply the k-means algorithm to your dataset, was it helpful? Did you get any insight? Comment on the number of cluster you used.\n",
    "\n",
    "- What if you used Hierarchical clustering? Any differences? \n",
    "\n",
    "\n",
    "In all above, justify your decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
